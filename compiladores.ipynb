{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugando as Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "p = re.compile('\".*\"|[a-zA-Z_]+[a-zA-Z0-9_]*|[0-9]+|[+|*|/|\\-|{|}|(|)|\\[|\\]|\\.|,|;|<|>|=|~|&]')\n",
    "\n",
    "entrada = \"\"\"{ } | ( ) [ ] . , ; + - * / & < > = ~\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "g = p.findall(entrada)\n",
    "print(len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = [\n",
    "    \"class\", \"constructor\", \"function\", \"method\", \"field\", \"static\",\n",
    "    \"var\", \"int\", \"char\", \"boolean\", \"void\", \"true\", \"false\", \"null\",\n",
    "    \"this\", \"let\", \"do\", \"if\", \"else\", \"while\", \"return\"\n",
    "]\n",
    "\n",
    "symbols = [\n",
    "    \"{\", \"}\", \"(\", \")\", \"[\", \"]\",\n",
    "    \".\", \",\", \";\", \"+\", \"-\", \"*\", \"/\",\n",
    "    \"&\", \"|\", \"<\", \">\", \"=\", \"~\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação do Analisador Lexico - André e Daniela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from __future__ import print_function\n",
    "\n",
    "class AnalisadorLexico:\n",
    "    \n",
    "    p = re.compile('\".*\"|[a-zA-Z_]+[a-zA-Z0-9_]*|[0-9]+|[+|*|/|\\-|{|}|(|)|\\[|\\]|\\.|,|;|<|>|=|~|&]')\n",
    "\n",
    "    idPattern = \"[a-zA-Z_]+[a-zA-Z0-9_]*\"\n",
    "    \n",
    "    intPattern = \"[0-9]+\"   \n",
    "    \n",
    "    strPattern = '\".*\"'\n",
    "    \n",
    "    symbolPattern = \"|[+|*|/|\\-|{|}|(|)|\\[|\\]|\\.|,|;|<|>|=|~]\"\n",
    "    \n",
    "    commands = [\n",
    "        \"class\", \"constructor\", \"function\", \"method\", \"field\", \"static\",\n",
    "        \"var\", \"int\", \"char\", \"boolean\", \"void\", \"true\", \"false\", \"null\",\n",
    "        \"this\", \"let\", \"do\", \"if\", \"else\", \"while\", \"return\"\n",
    "    ]\n",
    "    symbols = [\n",
    "        \"{\", \"}\", \"(\", \")\", \"[\", \"]\",\n",
    "        \".\", \",\", \";\", \"+\", \"-\", \"*\", \"/\",\n",
    "        \"&\", \"|\", \"<\", \">\", \"=\", \"~\"\n",
    "    ]\n",
    "    \n",
    "    def symbolReplace(self, symbol):\n",
    "        if(symbol == \"<\"):\n",
    "            return \"&lt\"\n",
    "        elif(symbol == \">\"):\n",
    "            return \"&gt\"\n",
    "        elif(symbol == '\"'):\n",
    "            return \"&quot\"\n",
    "        elif(symbol == '&'):\n",
    "            return \"&amp\"\n",
    "        else:\n",
    "            return symbol\n",
    "            \n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.file = open(file_path, \"r\").read()\n",
    "        self.tokens = p.findall(self.file)\n",
    "        self.currentTokenIndex = 0\n",
    "    \n",
    "    def hasMoreTokens(self):\n",
    "        return self.currentTokenIndex <= len(self.tokens)-1\n",
    "        \n",
    "    def advance(self):\n",
    "        if(self.hasMoreTokens()):\n",
    "            self.currentTokenIndex += 1\n",
    "            \n",
    "            \n",
    "    def tokenType(self, token):\n",
    "        \n",
    "        if(re.match(self.idPattern, token)):\n",
    "            if(token in self.commands):\n",
    "                return \"<keyword> {} </keyword>\".format(token)\n",
    "            else:\n",
    "                return \"<identifier> {} </identifier>\".format(token)\n",
    "                \n",
    "        elif(re.match(self.intPattern, token)):\n",
    "            return \"<integerConstant> {} </integerConstant>\".format(token)\n",
    "            \n",
    "        elif(re.match(self.strPattern, token)):\n",
    "            return \"<stringConstant> {} </stringConstant>\".format(token[1:len(token)-1])\n",
    "\n",
    "        elif(re.match(self.symbolPattern, token)):\n",
    "            return \"<symbol> {} </symbol> \".format(self.symbolReplace(token))\n",
    "        else:\n",
    "            return \"<error, not identified> {} </error, not identified> \".format(token)\n",
    "\n",
    "                                                        \n",
    "    def analise(self):\n",
    "        \n",
    "        file = open(\"result.txt\", \"w\")\n",
    "        \n",
    "        print(\"<tokens>\", file=file)\n",
    "        \n",
    "        while self.hasMoreTokens():\n",
    "            \n",
    "            print(self.tokenType(self.tokens[self.currentTokenIndex]), file=file)\n",
    "            \n",
    "            self.advance()\n",
    "        \n",
    "        print(\"</tokens>\", file=file)\n",
    "\n",
    "        file.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "                \n",
    "        \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = AnalisadorLexico(\"code.jack\")\n",
    "\n",
    "a.analise()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myd = {\n",
    "    \n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
